{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alhichri/RS-DeepSuperLearner/blob/main/convert_large_datasets_to_tfrecords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ofvbWCCr6u9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ea6a59-3bc7-4b16-ebd2-24a0e539e6ac"
      },
      "source": [
        "import tensorflow as tf\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pathlib\n",
        "import glob\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,  classification_report, accuracy_score\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "tf.__version__\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive' , force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qth0e2vKsEDy"
      },
      "source": [
        "# import pathlib\n",
        "# data_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "#                                          fname='flower_photos', untar=True)\n",
        "# print(data_dir)\n",
        "\n",
        "# data_dir = pathlib.Path(data_dir)\n",
        "# print(data_dir)\n",
        "\n",
        "datatsets_path = \"/content/gdrive/My Drive/RS_datasets/\"\n",
        "# dataset = 'AID'; image_format = '.png';   folds_split_text_file_name = 'AID_folds_split_text_file.txt'\n",
        "# dataset = 'PatternNet' ; image_format = '.jpg';     folds_split_text_file_name = 'PatternNet_folds_split_text_file.txt'\n",
        "dataset = 'NWPU_RESISC45' ; image_format = '.jpg';      folds_split_text_file_name = 'NWPU_RESISC45_folds_split_text_file.txt'\n",
        "\n",
        "data_dir = datatsets_path+dataset+ '/'; print(data_dir)\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "\n",
        "image_count = len(list(data_dir.glob('*/*'+image_format)))\n",
        "\n",
        "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
        "num_of_classes = len(CLASS_NAMES)\n",
        "print(CLASS_NAMES)\n",
        "print(num_of_classes)\n",
        "\n",
        "class_size = np.zeros((num_of_classes)).astype('int')\n",
        "for cn in range(num_of_classes):\n",
        "    path_name = datatsets_path+dataset + '/' + CLASS_NAMES[cn]\n",
        "    data_dir = pathlib.Path(path_name)\n",
        "    class_size[cn] = len(list(data_dir.glob('*'+image_format)))\n",
        "    print('path name and class size: ' , path_name , class_size[cn])\n",
        "\n",
        "\n",
        "cn = 2\n",
        "path_name = datatsets_path+dataset + '/' + CLASS_NAMES[cn]\n",
        "data_dir = pathlib.Path(path_name)\n",
        "file_names_with_paths = list(data_dir.glob('*'+image_format))\n",
        "# for i in range(class_size[cn]):\n",
        "#     print(file_names_with_paths[i])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka7AWTzhsETw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5d93f2c-f06a-4e85-89ca-732591803a88"
      },
      "source": [
        "print('num of classes: ', num_of_classes)\n",
        "print('Class names: ', CLASS_NAMES)\n",
        "print('Total number of images: ' , image_count)\n",
        "for cn in range(num_of_classes):\n",
        "    print('Class name and size: ' , CLASS_NAMES[cn] , class_size[cn])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num of classes:  45\n",
            "Class names:  ['lake' 'palace' 'chaparral' 'dense_residential' 'parking_lot'\n",
            " 'tennis_court' 'island' 'desert' 'meadow' 'beach' 'thermal_power_station'\n",
            " 'cloud' 'terrace' 'sea_ice' 'snowberg' 'roundabout' 'sparse_residential'\n",
            " 'runway' 'airplane' 'storage_tank' 'overpass' 'church' 'wetland' 'bridge'\n",
            " 'commercial_area' 'intersection' 'basketball_court' 'freeway' 'mountain'\n",
            " 'railway' 'airport' 'circular_farmland' 'baseball_diamond'\n",
            " 'mobile_home_park' 'rectangular_farmland' 'railway_station' 'river'\n",
            " 'ground_track_field' 'industrial_area' 'stadium' 'ship' 'harbor'\n",
            " 'medium_residential' 'forest' 'golf_course']\n",
            "Total number of images:  31503\n",
            "Class name and size:  lake 700\n",
            "Class name and size:  palace 700\n",
            "Class name and size:  chaparral 700\n",
            "Class name and size:  dense_residential 700\n",
            "Class name and size:  parking_lot 700\n",
            "Class name and size:  tennis_court 700\n",
            "Class name and size:  island 700\n",
            "Class name and size:  desert 700\n",
            "Class name and size:  meadow 700\n",
            "Class name and size:  beach 700\n",
            "Class name and size:  thermal_power_station 700\n",
            "Class name and size:  cloud 702\n",
            "Class name and size:  terrace 700\n",
            "Class name and size:  sea_ice 700\n",
            "Class name and size:  snowberg 700\n",
            "Class name and size:  roundabout 700\n",
            "Class name and size:  sparse_residential 700\n",
            "Class name and size:  runway 700\n",
            "Class name and size:  airplane 700\n",
            "Class name and size:  storage_tank 700\n",
            "Class name and size:  overpass 700\n",
            "Class name and size:  church 700\n",
            "Class name and size:  wetland 700\n",
            "Class name and size:  bridge 700\n",
            "Class name and size:  commercial_area 700\n",
            "Class name and size:  intersection 700\n",
            "Class name and size:  basketball_court 700\n",
            "Class name and size:  freeway 700\n",
            "Class name and size:  mountain 700\n",
            "Class name and size:  railway 700\n",
            "Class name and size:  airport 700\n",
            "Class name and size:  circular_farmland 700\n",
            "Class name and size:  baseball_diamond 700\n",
            "Class name and size:  mobile_home_park 700\n",
            "Class name and size:  rectangular_farmland 700\n",
            "Class name and size:  railway_station 700\n",
            "Class name and size:  river 700\n",
            "Class name and size:  ground_track_field 700\n",
            "Class name and size:  industrial_area 700\n",
            "Class name and size:  stadium 700\n",
            "Class name and size:  ship 700\n",
            "Class name and size:  harbor 701\n",
            "Class name and size:  medium_residential 700\n",
            "Class name and size:  forest 700\n",
            "Class name and size:  golf_course 700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DkFvS-KsEdQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "outputId": "211c6801-54b4-4069-ef32-688196a90548"
      },
      "source": [
        "#################################################################################################\n",
        "####### This code reads images and saves them in tfrecords files\n",
        "####### Data is  divided into folds and each fold is saved in a tfrecords\n",
        "#################################################################################################\n",
        "nfolds = 20;\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "# Create a dictionary with features that may be relevant.\n",
        "def image_example(image_string, label):\n",
        "  image_shape = tf.image.decode_jpeg(image_string).shape\n",
        "\n",
        "  feature = {\n",
        "      #'height': _int64_feature(image_shape[0]),\n",
        "      #'width': _int64_feature(image_shape[1]),\n",
        "      #'depth': _int64_feature(image_shape[2]),\n",
        "      'label': _int64_feature(label),\n",
        "      'image_raw': _bytes_feature(image_string),\n",
        "  }\n",
        "\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "F_idx = []; list_of_files= []\n",
        "for label in range(num_of_classes):\n",
        "    # print('Class name and size: ' , CLASS_NAMES[label] , class_size[label])\n",
        "    curr_class_idx = np.arange (class_size[label])\n",
        "    # indeces_permuted = np.random.permutation(curr_class_idx)\n",
        "    fold_size = int(np.round(  class_size[label] / nfolds ))\n",
        "    F_idx.append(   curr_class_idx   )\n",
        "    # print(  F_idx[label]   )\n",
        "    path_name = datatsets_path+dataset + '/' + CLASS_NAMES[label] +'/'\n",
        "    print('current class: ', label, ' name: ' ,  CLASS_NAMES[label], 'Size: ' , class_size[label], 'take in fold: ' , fold_size )\n",
        "    data_dir = pathlib.Path(path_name)\n",
        "    flist = list(data_dir.glob('*'+image_format)) \n",
        "    list_of_files.append(  flist   )\n",
        "\n",
        "print(datatsets_path+dataset)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current class:  0  name:  lake Size:  700 take in fold:  35\n",
            "current class:  1  name:  palace Size:  700 take in fold:  35\n",
            "current class:  2  name:  chaparral Size:  700 take in fold:  35\n",
            "current class:  3  name:  dense_residential Size:  700 take in fold:  35\n",
            "current class:  4  name:  parking_lot Size:  700 take in fold:  35\n",
            "current class:  5  name:  tennis_court Size:  700 take in fold:  35\n",
            "current class:  6  name:  island Size:  700 take in fold:  35\n",
            "current class:  7  name:  desert Size:  700 take in fold:  35\n",
            "current class:  8  name:  meadow Size:  700 take in fold:  35\n",
            "current class:  9  name:  beach Size:  700 take in fold:  35\n",
            "current class:  10  name:  thermal_power_station Size:  700 take in fold:  35\n",
            "current class:  11  name:  cloud Size:  702 take in fold:  35\n",
            "current class:  12  name:  terrace Size:  700 take in fold:  35\n",
            "current class:  13  name:  sea_ice Size:  700 take in fold:  35\n",
            "current class:  14  name:  snowberg Size:  700 take in fold:  35\n",
            "current class:  15  name:  roundabout Size:  700 take in fold:  35\n",
            "current class:  16  name:  sparse_residential Size:  700 take in fold:  35\n",
            "current class:  17  name:  runway Size:  700 take in fold:  35\n",
            "current class:  18  name:  airplane Size:  700 take in fold:  35\n",
            "current class:  19  name:  storage_tank Size:  700 take in fold:  35\n",
            "current class:  20  name:  overpass Size:  700 take in fold:  35\n",
            "current class:  21  name:  church Size:  700 take in fold:  35\n",
            "current class:  22  name:  wetland Size:  700 take in fold:  35\n",
            "current class:  23  name:  bridge Size:  700 take in fold:  35\n",
            "current class:  24  name:  commercial_area Size:  700 take in fold:  35\n",
            "current class:  25  name:  intersection Size:  700 take in fold:  35\n",
            "current class:  26  name:  basketball_court Size:  700 take in fold:  35\n",
            "current class:  27  name:  freeway Size:  700 take in fold:  35\n",
            "current class:  28  name:  mountain Size:  700 take in fold:  35\n",
            "current class:  29  name:  railway Size:  700 take in fold:  35\n",
            "current class:  30  name:  airport Size:  700 take in fold:  35\n",
            "current class:  31  name:  circular_farmland Size:  700 take in fold:  35\n",
            "current class:  32  name:  baseball_diamond Size:  700 take in fold:  35\n",
            "current class:  33  name:  mobile_home_park Size:  700 take in fold:  35\n",
            "current class:  34  name:  rectangular_farmland Size:  700 take in fold:  35\n",
            "current class:  35  name:  railway_station Size:  700 take in fold:  35\n",
            "current class:  36  name:  river Size:  700 take in fold:  35\n",
            "current class:  37  name:  ground_track_field Size:  700 take in fold:  35\n",
            "current class:  38  name:  industrial_area Size:  700 take in fold:  35\n",
            "current class:  39  name:  stadium Size:  700 take in fold:  35\n",
            "current class:  40  name:  ship Size:  700 take in fold:  35\n",
            "current class:  41  name:  harbor Size:  701 take in fold:  35\n",
            "current class:  42  name:  medium_residential Size:  700 take in fold:  35\n",
            "current class:  43  name:  forest Size:  700 take in fold:  35\n",
            "current class:  44  name:  golf_course Size:  700 take in fold:  35\n",
            "/content/gdrive/My Drive/RS_datasets/NWPU_RESISC45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUzCfk2ZxW6c"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# print('num of classes: ', num_of_classes)\n",
        "# folds_split_text_file = open(\"NWPU_RESISC45_folds_split_text_file.txt\",\"w\") \n",
        "# for fn in range(nfolds):\n",
        "#     fixed_number = '%02d' %fn; \n",
        "#     tfrecord_train_file = datatsets_path+dataset + '_tfrecords/' +  'tfrecords.train.fold'+fixed_number\n",
        "#     print(tfrecord_train_file)\n",
        "#     folds_split_text_file.write('fold number: ' + fixed_number + ' \\n')\n",
        "#     for label in range(num_of_classes):\n",
        "#       label_fixed_size_str = '%02d' %label; \n",
        "#       curr_class_idx = np.arange (class_size[label])\n",
        "#       fold_size = int(np.round(  class_size[label] / nfolds ))\n",
        "#       idx =   F_idx[label] ; # list of images idx permuted        \n",
        "#       list_of_indeces = idx[ fn*fold_size:(fn+1)*fold_size  ]  # get a list of idx from this class for this fold  \n",
        "#       if fn==(nfolds-1):\n",
        "#         list_of_indeces = idx[ -fold_size:  ]; \n",
        "#       path_name = datatsets_path+dataset + '/' + CLASS_NAMES[label] +'/'\n",
        "#       # path_name = datatsets_path+dataset + '/' + CLASS_NAMES[cn]\n",
        "#       str_to_be_written_in_text_file = label_fixed_size_str\n",
        "#       for i in range(fold_size):\n",
        "#         file_num = '%04d'%list_of_indeces[i]\n",
        "#         file_name = 'img'+file_num\n",
        "#         file_name_with_path = path_name + file_name  +  image_format\n",
        "#         str_to_be_written_in_text_file = str_to_be_written_in_text_file + ' ' + file_num\n",
        "\n",
        "#       folds_split_text_file.write(str_to_be_written_in_text_file +'\\n' )\n",
        "#       # print('current class: '+label_fixed_size_str+ ' name: ' ,  CLASS_NAMES[label], 'Size: ' , class_size[label], 'take in fold: ' , fn*fold_size , 'to ', (fn+1)*fold_size)\n",
        "#       print('current class: '+label_fixed_size_str+ ' name: ' ,  CLASS_NAMES[label], 'Size: ' , class_size[label], 'take in fold: ' + str_to_be_written_in_text_file)\n",
        "\n",
        "# folds_split_text_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOoY5-akXr9x"
      },
      "source": [
        "# this code only shows the files to be written to disk, it does not actually write\n",
        "path_to_fold_splits_files = '/content/gdrive/My Drive/RS_datasets/splits_of_datasets_into_folds/'  \n",
        "\n",
        "print('num of classes: ', num_of_classes)\n",
        "folds_split_text_file = open(path_to_fold_splits_files+folds_split_text_file_name,\"r+\") \n",
        "for fn in range(nfolds):\n",
        "  next_line = folds_split_text_file.readline()\n",
        "  fold_number = next_line[-4:-1]\n",
        "  tfrecord_train_file = datatsets_path+dataset + '_tfrecords/' +  'tfrecords.train.fold'+fold_number\n",
        "  print('foldNum: '+ fold_number+ tfrecord_train_file)\n",
        "  for label in range(num_of_classes):\n",
        "    className = CLASS_NAMES[label]\n",
        "    next_line = folds_split_text_file.readline()\n",
        "    image_numbers = next_line.split()\n",
        "    print('foldNum: '+ fold_number+ 'classNum: ' + image_numbers[0]+ ' numImages: ',  len(image_numbers[1:])  , ' name: ' + CLASS_NAMES[label] ,  image_numbers[1:])\n",
        "\n",
        "\n",
        "    path_name = datatsets_path+dataset + '/' + CLASS_NAMES[label] +'/'\n",
        "    # path_name = datatsets_path+dataset + '/' + CLASS_NAMES[cn]\n",
        "    for i in range(len(image_numbers)-1):\n",
        "      file_name = 'img'+image_numbers[i+1]\n",
        "      file_name_with_path = path_name + file_name  +  image_format\n",
        "      # print( file_name_with_path )\n",
        "\n",
        "folds_split_text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPo6GRiC0dGs"
      },
      "source": [
        "\n",
        "path_to_fold_splits_files = '/content/gdrive/My Drive/RS_datasets/splits_of_datasets_into_folds/'  \n",
        "\n",
        "print('num of classes: ', num_of_classes)\n",
        "folds_split_text_file = open(path_to_fold_splits_files+folds_split_text_file_name,\"r+\") \n",
        "for fn in range(nfolds):\n",
        "  next_line = folds_split_text_file.readline()\n",
        "  fold_number = next_line[-4:-1]\n",
        "  if not(fn>=15 and fn<20):\n",
        "    for label in range(num_of_classes):\n",
        "        className = CLASS_NAMES[label]\n",
        "        next_line = folds_split_text_file.readline()\n",
        "        image_numbers = next_line.split()\n",
        "        print('foldNum: '+ fold_number+ 'classNum: ' + image_numbers[0]+ ' numImages: ',  len(image_numbers[1:]) )\n",
        "  else:\n",
        "    tfrecord_train_file = datatsets_path+dataset + '_tfrecords/' +  'tfrecords.train.fold'+fold_number\n",
        "    print('foldNum: '+ fold_number+ tfrecord_train_file)\n",
        "    with tf.io.TFRecordWriter(tfrecord_train_file) as writer:\n",
        "      for label in range(num_of_classes):\n",
        "        className = CLASS_NAMES[label]\n",
        "        next_line = folds_split_text_file.readline()\n",
        "        image_numbers = next_line.split()\n",
        "        print('foldNum: '+ fold_number+ 'classNum: ' + image_numbers[0]+ ' numImages: ',  len(image_numbers[1:])  , ' name: ' + CLASS_NAMES[label] , image_numbers[1:])\n",
        "\n",
        "\n",
        "        path_name = datatsets_path+dataset + '/' + CLASS_NAMES[label] +'/'\n",
        "        # path_name = datatsets_path+dataset + '/' + CLASS_NAMES[cn]\n",
        "        for i in range(len(image_numbers)-1):\n",
        "          file_name = 'img'+image_numbers[i+1]\n",
        "          file_name_with_path = path_name + file_name  +  image_format\n",
        "          # print( file_name_with_path )\n",
        "          image_string = open(file_name_with_path, 'rb').read()\n",
        "          tf_example = image_example(image_string, label)\n",
        "          writer.write(tf_example.SerializeToString())\n",
        "\n",
        "folds_split_text_file.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRl53HXkVLrg"
      },
      "source": [
        "# print('num of classes: ', num_of_classes)\n",
        "# folds_split_text_file = open(\"folds_split_text_file.txt\",\"w\") \n",
        "# for fn in range(nfolds):\n",
        "#     fixed_number = '%02d' %fn; folds_split_text_file.write('fold number: ' + fixed_number)\n",
        "#     tfrecord_train_file = datatsets_path+dataset + '_tfrecords/' +  'tfrecords.train.fold'+fixed_number\n",
        "#     print(tfrecord_train_file)\n",
        "#     with tf.io.TFRecordWriter(tfrecord_train_file) as writer:\n",
        "#       for label in range(num_of_classes):\n",
        "#         label_fixed_size_str = '%02d' %label; \n",
        "#         curr_class_idx = np.arange (class_size[label])\n",
        "#         fold_size = int(np.round(  class_size[label] / nfolds ))\n",
        "#         idx =   F_idx[label] ; # list of images idx permuted        \n",
        "#         list_of_indeces = idx[ fn*fold_size:(fn+1)*fold_size  ]  # get a list of idx from this class for this fold  \n",
        "#         if fn==(nfolds-1):\n",
        "#           list_of_indeces = idx[ -fold_size:  ]; \n",
        "#         path_name = datatsets_path+dataset + '/' + CLASS_NAMES[label] +'/'\n",
        "#         # path_name = datatsets_path+dataset + '/' + CLASS_NAMES[cn]\n",
        "#         str_to_be_written_in_text_file = label_fixed_size_str\n",
        "#         for i in range(fold_size):\n",
        "#           file_num = '%04d'%list_of_indeces[i]\n",
        "#           file_name = 'img'+file_num\n",
        "#           file_name_with_path = path_name + file_name  +  image_format\n",
        "#           # print( 'tfrecords.train.fold'+str(fn), 'image: ', file_name_with_path)\n",
        "#           image_string = open(file_name_with_path, 'rb').read()\n",
        "#           tf_example = image_example(image_string, label)\n",
        "#           writer.write(tf_example.SerializeToString())\n",
        "#           str_to_be_written_in_text_file = str_to_be_written_in_text_file + ' ' + file_num\n",
        "\n",
        "#         folds_split_text_file.write(str_to_be_written_in_text_file +'\\n' )\n",
        "#         # print('current class: '+label_fixed_size_str+ ' name: ' ,  CLASS_NAMES[label], 'Size: ' , class_size[label], 'take in fold: ' , fn*fold_size , 'to ', (fn+1)*fold_size)\n",
        "#         print('current class: '+label_fixed_size_str+ ' name: ' ,  CLASS_NAMES[label], 'Size: ' , class_size[label], 'take in fold: ' + str_to_be_written_in_text_file)\n",
        "\n",
        "# folds_split_text_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W76GH6ZuDb8"
      },
      "source": [
        "\n",
        "#################################################################################################\n",
        "####### This code can read image files from directories and save them as tfrecords\n",
        "####### All images in a given class are saved in one tfrecords\n",
        "#################################################################################################\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "# Create a dictionary with features that may be relevant.\n",
        "def image_example(image_string, label):\n",
        "  image_shape = tf.image.decode_jpeg(image_string).shape\n",
        "\n",
        "  feature = {\n",
        "      #'height': _int64_feature(image_shape[0]),\n",
        "      #'width': _int64_feature(image_shape[1]),\n",
        "      #'depth': _int64_feature(image_shape[2]),\n",
        "      'label': _int64_feature(label),\n",
        "      'image_raw': _bytes_feature(image_string),\n",
        "  }\n",
        "\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "# Write the raw image files to `images.tfrecords`.\n",
        "# First, process the two images into `tf.Example` messages.\n",
        "# Then, write to a `.tfrecords` file.\n",
        "\n",
        "\n",
        "for label_seq in range(num_of_classes):\n",
        "  class_name = CLASS_NAMES0[label_seq]\n",
        "  print(str(data_dir)+'/'+class_name)\n",
        "  curr_class_dir = str(data_dir)+'/'+class_name\n",
        "  list_of_images = list(glob.glob(curr_class_dir+'/*.png'))\n",
        "  count_of_images = len(list_of_images)\n",
        "  train_split = int(count_of_images/2)\n",
        "  print(list_of_images)\n",
        "  #train_split = 2\n",
        "  # tfrecord_train_file = '/content/gdrive/My Drive/RS_datasets/NWPU_tfrecords/tfrecords.train.'+class_name\n",
        "  # label = label_seq\n",
        "  # with tf.io.TFRecordWriter(tfrecord_train_file) as writer:\n",
        "  #   for i in range(train_split):\n",
        "  #     filename = list_of_images[i]; \n",
        "  #     image_string = open(filename, 'rb').read()\n",
        "  #     tf_example = image_example(image_string, label)\n",
        "  #     writer.write(tf_example.SerializeToString())\n",
        "  # tfrecord_validation_file = '/content/gdrive/My Drive/RS_datasets/NWPU_tfrecords/tfrecords.test.'+class_name\n",
        "  # with tf.io.TFRecordWriter(tfrecord_validation_file) as writer:\n",
        "  #   for i in range(train_split):\n",
        "  #     filename = list_of_images[i+train_split]; \n",
        "  #     image_string = open(filename, 'rb').read()\n",
        "  #     tf_example = image_example(image_string, label)\n",
        "  #     writer.write(tf_example.SerializeToString())\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}